{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of extract_MODIS_LST_4m_GEE_my_lon_lat_original.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amrit-thapa-2044/ICIMOD_permafrost_training_2022/blob/main/Copy_of_extract_MODIS_LST_4m_GEE_my_lon_lat_original.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*This notebook is prepared for the participants of the regional training on [Analysing permafrost in the Hindu Kush Himalaya using open access tools](https://www.icimod.org/event/analysing-permafrost-in-the-hindu-kush-himalaya-using-open-access-tools/) by [ICIMOD](https://www.icimod.org/) through its [Cryosphere Initiative](https://www.icimod.org/initiative/cryosphere/) under the Regional Programme on [River Basins and Cryosphere](https://www.icimod.org/regional-programme/river-basins-and-cryosphere/) in collaboration with [Kathmandu University]() and [Tribhuvan University](http://www.tribhuvan-university.edu.np/).*\n",
        "\n",
        "*The Cryosphere Initiative is supported by the Government of Norway and Swiss Agency for Development and Cooperation.*\n",
        "\n",
        "\n",
        "Coded by: \\\n",
        "Amrit Thapa \\\n",
        "Email: amrit.thapa@icimod.org \\\n",
        "GitHub: https://github.com/amrit-thapa-2044\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "kZoj_KdpSLtH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Why to analyze Land Surface Temperature (LST) ?\n",
        "\n",
        "\n",
        "- LST is an important parameter for the energy budget of permafrost environments.\n",
        "- LST values can help distinguish between frozen and unfrozen ground."
      ],
      "metadata": {
        "id": "nel_3Dycn6K2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Authenticate GEE and initiate library\n",
        "Earth Engine Python API is installed by default in Google Colaboratory, so all that needs to be done is import it and authenticate it. "
      ],
      "metadata": {
        "id": "pcBNHLmizgt4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4iMZiyyuVdV"
      },
      "outputs": [],
      "source": [
        "#load/import library\n",
        "import ee\n",
        "\n",
        "# Trigger the authentication flow.\n",
        "ee.Authenticate()\n",
        "\n",
        "# Initialize the library.\n",
        "ee.Initialize()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each time that you start Colab, if you restart your Colab kernel, or if your Colab virtual machine is recycled due to inactivity, it must be done."
      ],
      "metadata": {
        "id": "nXKOVWvwmsaF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above step allows us to communicate with GEE. Now, we are set to pull data from Earth Engine's public data archive. You can explore dataset available in [Earth Engine's public data archive](https://developers.google.com/earth-engine/datasets)."
      ],
      "metadata": {
        "id": "pRtsKGxenEzf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define user variables\n",
        "Let's define some variables to extract MODIS LST. The mandatory variables to be defined are: \n",
        "- the [sensor/satellite](https://developers.google.com/earth-engine/datasets/catalog/MODIS_006_MYD11A1#description) to be used\n",
        "- the time period to cover\n",
        "- [band/variable](https://developers.google.com/earth-engine/datasets/catalog/MODIS_006_MYD11A1) name as sensors can have more than one variable\n",
        "- latitude and longitude to use for the data extraction\n",
        "- the spatial resolution of the data (scale)"
      ],
      "metadata": {
        "id": "U-6GLGsF5WRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the name of the sensor/satellite to download data\n",
        "sensor='MYD11A1' # MOD11A1 or MYD11A1\n",
        "\n",
        "# initial date of interest (inclusive).\n",
        "i_date = '2003-01-01'\n",
        "\n",
        "# Final date of interest (exclusive).\n",
        "f_date = '2020-12-31'\n",
        "\n",
        "# define variable of interest\n",
        "my_variable='LST_Night_1km' # 'LST_Day_1km' or 'LST_Night_1km'\n",
        "\n",
        "# Define the location of your interest as point geometry\n",
        "my_lon = 86\n",
        "my_lat = 28.5\n",
        "\n",
        "# spatial resolution of the product\n",
        "scale = 1000"
      ],
      "metadata": {
        "id": "FB81OuuQ5cMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert longitude and latitude to geometry\n",
        "In GEE the feature class (point, line and polygon ) has to be imported as a geometry object. For this exercise, we are interested in extracting data at a point location. So, let's convert longitude and latitude to a point geometry.\n",
        "\n",
        "This can be done by using ***ee.Geometry.Point*** function. It takes two arguments (*coords, proj* (optional)).\n",
        "- *coords*:\ta list of two [x,y] coordinates in the given projection.\n",
        "- *proj*:\tthe projection of this geometry, or EPSG:4326 if unspecified."
      ],
      "metadata": {
        "id": "yeRhVYYAZhUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_point = ee.Geometry.Point(my_lon, my_lat)"
      ],
      "metadata": {
        "id": "xFtnWg6JdW78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load image collection\n",
        "Our next step is to load the image collection (stack of images) that we want to download. This can be done by calling the ***ee.ImageCollection*** function. By pasting an asset ID into the ImageCollection constructor, an ImageCollection can be loaded from Earth Engine. The ID of the ImageCollection can be found in the [data catalog](https://developers.google.com/earth-engine/datasets/catalog). The code below loads the MODIS Aqua LST image collection."
      ],
      "metadata": {
        "id": "o_DB8Ct_zvAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the MODIS land surface temperature collection.\n",
        "lst = ee.ImageCollection('MODIS/006/'+sensor)"
      ],
      "metadata": {
        "id": "9bLAfsouup6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filter image collection\n",
        "We would now like to select specific bands in the image collection using the ***select*** function. For the purpose of this example, we want MODIS LST data. This product has different [bands](https://developers.google.com/earth-engine/datasets/catalog/MODIS_006_MYD11A1). Now let's download LST_Night_1km band. Furthermore, we can use the ***filterDate*** function to filter dates at the same time. Each filter is connected to another using the dot (***.***) operator."
      ],
      "metadata": {
        "id": "GHvFbjckz4HC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selection of appropriate bands and dates for LST.\n",
        "lst = lst.select(my_variable).filterDate(i_date, f_date)"
      ],
      "metadata": {
        "id": "FNFXKE0guvlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract value from image collection\n",
        "In above steps, we loaded the image collection and filtered the image collection to select specific band and time slot. Now we are ready to extract the data at point location. This can be done by applying **getRegion** function.\n",
        "\n",
        "The expression for this function is \n",
        "\n",
        "*ImageCollection*.**getRegion**(*geometry, scale, crs*)\n",
        "\n",
        "- *ImageCollection*: image collection to extract data from.\n",
        "- *geometry*: region over which to extract data.\n",
        "- *scale*: nominal scale in meters of the projection to work in.\n",
        "- *crs*: projection to work in.\n"
      ],
      "metadata": {
        "id": "_MnOGpHt0JwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the data for the pixel intersecting our point.\n",
        "lst_my_point = lst.getRegion(my_point, scale).getInfo()"
      ],
      "metadata": {
        "id": "V2EDeG9EvUAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview first 6 rows of the result.\n",
        "lst_my_point[:6]"
      ],
      "metadata": {
        "id": "Uy0OP4UXuwzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert result to dataframe\n",
        "The output is an array. We would like to plot the data using ggplot and export the output as a CSV. To do this, we need data in dataframe format. Now, let's create a function to convert the array to a dataframe. We have already discussed how to define a function in Python. "
      ],
      "metadata": {
        "id": "vKluVMex0V4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def ee_array_to_df(arr, list_of_bands):\n",
        "    \"\"\"Transforms client-side ee.Image.getRegion array to pandas.DataFrame.\"\"\"\n",
        "    df = pd.DataFrame(arr)\n",
        "\n",
        "    # Rearrange the header.\n",
        "    headers = df.iloc[0]\n",
        "    df = pd.DataFrame(df.values[1:], columns=headers)\n",
        "\n",
        "    # Remove rows without data inside.\n",
        "    df = df[['longitude', 'latitude', 'time', *list_of_bands]].dropna()\n",
        "\n",
        "    # Convert the data to numeric values.\n",
        "    for band in list_of_bands:\n",
        "        df[band] = pd.to_numeric(df[band], errors='coerce')\n",
        "\n",
        "    # Convert the time field into a datetime.\n",
        "    df['datetime'] = pd.to_datetime(df['time'], unit='ms')\n",
        "\n",
        "    # Keep the columns of interest.\n",
        "    df = df[['time','datetime',  *list_of_bands]]\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "hOIeL7p3v17X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply function to convert array to dataframe\n",
        "lst_df_my_point = ee_array_to_df(lst_my_point,[my_variable])"
      ],
      "metadata": {
        "id": "-fj5qquM0vaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert LST from Kelvin to Degree Celsius\n",
        "MODIS LST data are available in Kelvin with a scale factor of 0.02. But it can be easily converted to an absolute value (degrees Celsius) by using the following conversion:\n",
        "\n",
        "$LST (Degree C)= 0.02 * LST(Kelvin) - 273.15$.\n",
        " \n",
        " Let's do this.We will define a function and apply it over entire dataframe to convert Kelvin to degree Celsius.\n",
        "\n",
        "In python, we use **def** for defining a function. It uses the following components.\n",
        "\n",
        "- keyword **def** that marks the start of the function header.\n",
        "- a function name to uniquely identify the function. \n",
        "- a colon (:) to mark the end of the function header.\n",
        "- optional documentation string (docstring) to describe what the function does.\n",
        "- one or more valid python statements that make up the function body.\n",
        "- statements must have the same indentation level (usually 4 spaces).\n",
        "- optional return statement to return a value from the function.\n"
      ],
      "metadata": {
        "id": "QetD7MJI0fug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def t_modis_to_celsius(t_modis):\n",
        "    \"\"\"Converts MODIS LST units to degrees Celsius.\"\"\"\n",
        "    t_celsius =  0.02*t_modis - 273.15\n",
        "    return t_celsius\n",
        "\n",
        "# Apply the function to get temperature in celsius.\n",
        "lst_df_my_point[my_variable] = lst_df_my_point[my_variable].apply(t_modis_to_celsius)"
      ],
      "metadata": {
        "id": "fDNbfH0Yv_5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize head of the output\n",
        "lst_df_my_point.head()"
      ],
      "metadata": {
        "id": "1Km1DO0iwLib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# delete first column as we have already converted time to date \n",
        "del lst_df_my_point[\"time\"]\n",
        "lst_df_my_point.head()"
      ],
      "metadata": {
        "id": "ERx91xHKzJiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have already converted time to date, so we can delete the first column."
      ],
      "metadata": {
        "id": "XmdLTE8sAgny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize downloaded visualization\n",
        "For this notebook, we will use the python package [plotnine](https://plotnine.readthedocs.io/). Plotnine is an implementation of a grammar of graphics in Python. This package is based on [ggplot2](https://ggplot2.tidyverse.org/) from the [R](https://cran.r-project.org/) programming language. Additionally, we use [mizani](https://mizani.readthedocs.io/), a python library that provides the function necessary to create scales for a graphics system. It is based on the R [scales](https://scales.r-lib.org/) package. The colab notebook already contains both of these packages. They just need to be loaded."
      ],
      "metadata": {
        "id": "Ty7KTiNU09XC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load required packages\n",
        "from plotnine import* # asterisk (*) means load all functions from plotnine\n",
        "from mizani.breaks import date_breaks\n",
        "from mizani.formatters import date_format"
      ],
      "metadata": {
        "id": "zAaH6gRw1MAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's make a plot. The ggplot funcion uses basic building blocks according to the grammar of graphics as follows\n",
        "\n",
        "- data: data + a set of aesthetic mappings that describe variables mapping\n",
        "- geom: geometric objects represent what you actually see on the plot: points, lines, polygons, etc.\n",
        " More detail about ggplot in python is [here](https://monashdatafluency.github.io/python-workshop-base/modules/plotting_with_ggpl).\n",
        "\n"
      ],
      "metadata": {
        "id": "OeE9zRokQGXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_daily_LST=(\n",
        "    ggplot(lst_df_my_point)  # What data to use\n",
        "    + geom_line(aes(x=\"datetime\", y=\"LST_Night_1km\"),colour='red')\n",
        "    +ylab('LST (degree C)')+xlab('Year')\n",
        "    + scale_x_datetime(breaks=date_breaks('2 years'), labels=date_format('%Y-%m'))\n",
        "    +ggtitle(sensor+' '+my_variable+' at lon= '+str(my_lon)+' lat ='+str(my_lat))\n",
        "    +theme(figure_size=(10, 5)) #x,y)\n",
        ")\n",
        "\n",
        "print(plot_daily_LST)"
      ],
      "metadata": {
        "id": "VMHDuybS5zsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert daily LST to annual values (MAST)\n",
        "\n",
        "MAST (mean annual surface temperatures) is an important permafrost index, used to detect the presence of permafrost. MAST is derived by aggregating daily LST at an annual scale. \n",
        "\n",
        "Let's take a look at the daily LST conversion. This is done using the resample function. Details about the use of this function is available [here](https://www.earthdatascience.org/courses/use-data-open-source-python/use-time-series-data-in-python/date-time-types-in-pandas-python/resample-time-series-data-pandas-python/).\n",
        "\n",
        "It is necessary to convert the date to an index before using the resample function.\n"
      ],
      "metadata": {
        "id": "d3GTLmKGtyem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert date colum to index\n",
        "df_lst_my_point = lst_df_my_point.set_index('datetime') \n",
        "\n",
        "# aggregate daily to annual mean values\n",
        "df_annual_LST=df_lst_my_point.resample('Y').mean()\n",
        "\n",
        "# visualize first five rows to check output dataframe\n",
        "df_annual_LST.head()"
      ],
      "metadata": {
        "id": "eTJ3ni0Fya0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above dataframe, we notice that the datetime column is no more a column but they are now row names. So, let's restructure rows name as a column and produce a plot."
      ],
      "metadata": {
        "id": "STVDu4yn892b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a column name for row  <if you rerun this line you may get error, in that case run from immediate step>\n",
        "df_annual_LST.index.name = 'Year'\n",
        "\n",
        "# reset index as a column\n",
        "df_annual_LST.reset_index(inplace=True)\n",
        "\n",
        "# visualize  first five rows\n",
        "df_annual_LST.head()"
      ],
      "metadata": {
        "id": "e_TxX1gP7Emc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's visualize the MAST using ggplot."
      ],
      "metadata": {
        "id": "mpzUIE8z53V3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_MAAT=(\n",
        "    ggplot(df_annual_LST)  # What data to use\n",
        "    + geom_line(aes(x=\"Year\", y=\"LST_Night_1km\"),colour='red')\n",
        "    + geom_point(aes(x=\"Year\", y=\"LST_Night_1km\"),colour='blue')\n",
        "    +ylab('MAST (degree C)')+xlab('Year')\n",
        "    + scale_x_datetime(breaks=date_breaks('1 years'), labels=date_format('%Y'))\n",
        "    +ggtitle('MAST from '+sensor+' '+my_variable+' at lon= '+str(my_lon)+' lat ='+str(my_lat))\n",
        "    +theme(figure_size=(10, 5)) #x,y)\n",
        ")\n",
        "\n",
        "print(plot_MAAT)"
      ],
      "metadata": {
        "id": "wy-c7LV25_nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question: Assess the magnitude and pattern of mean annual land surface temperature (MAST) and discuss how it relates with the permafrost process in a group of 3-4 participants."
      ],
      "metadata": {
        "id": "vV_HsZjxrQ6v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export/download data to local machine\n",
        "Colab also provides a function to download data directly to the local machine. From the **google.colab** package, we can use the **files.download** function to download output.\n"
      ],
      "metadata": {
        "id": "U4oaa91-1N3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load necessary files\n",
        "from google.colab import files\n",
        "\n",
        "# define output filename\n",
        "my_filename=sensor+'_'+my_variable+'_lon_'+str(my_lon)+'_lat_'+str(my_lat)+'_'+i_date+'_'+f_date+'.csv'\n",
        "print('my file name is: ',my_filename)\n",
        "\n",
        "# Convert dataframe to csv\n",
        "lst_df_my_point.to_csv(my_filename, encoding = 'utf-8-sig') \n",
        "\n",
        "# download csv\n",
        "files.download(my_filename)"
      ],
      "metadata": {
        "id": "S-0z3Fu0yon8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is important to evaluate the accuracy and precision of the LST products before we use them. Remote sensing and reanalysis datasets are available along with metadata. Read the metadata carefully before using the data."
      ],
      "metadata": {
        "id": "oh4y7VexodiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment:\n",
        "- download MODIS LST data to your own point location over permafrost research site and convert to annual mean series (MAST).\n",
        "- make time series plot of MAST and discuss the nature of the magnitude of data in a group of 3-4 participants.\n",
        "- make a seasonal plot to understand monthly variability of daily LST data and discuss the pattern."
      ],
      "metadata": {
        "id": "6LUIg4fScKzP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ": <h1 align='center'>**THANK YOU**</h1>"
      ],
      "metadata": {
        "id": "_xxJIsz7jnpR"
      }
    }
  ]
}